{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovery of parameter correlations\n",
    "\n",
    "Here we evaluate whether we can recover any correlations between the $k$ and $s$ parameters in simulated participants who discount according to the modified Rachlin discount function (see [Vincent, & Stewart, 2020](https://doi.org/10.1016/j.cognition.2020.104203)).\n",
    "\n",
    "$$\n",
    "V(R, D, k) = R \\cdot \\frac{1}{1+(k \\cdot D)^s}\n",
    "$$\n",
    "\n",
    "where $R$ is a reward, delivered at a delay $D$. The parameters are:\n",
    "- $k$ is the normally interpreted as the discount rate. Although technically in this case it is the product of the discount rate and the constant term in Steven's Power Law.\n",
    "- $s$ is the exponent in Steven's Power Law."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, bernoulli, uniform, multivariate_normal, pearsonr\n",
    "import pymc3 as pm\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "# Initialize random number generator\n",
    "np.random.seed(1234)\n",
    "\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyMC3 version: {pm.__version__}\")\n",
    "\n",
    "# Install Black autoformatter with: pip install nb-black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARAMETERS = 2\n",
    "\n",
    "# group size of each simulation\n",
    "N = 40\n",
    "\n",
    "# sweep along these correlation coefficients\n",
    "r_vals = np.linspace(-0.8, 0.8, 30)\n",
    "\n",
    "# should we visualise the data and true (and recovered) discount functions for each simulation?\n",
    "should_visualise = False\n",
    "\n",
    "export_group_plots = True\n",
    "\n",
    "# export options\n",
    "export = False\n",
    "out_dir = \"output/\"\n",
    "\n",
    "# PyMC3 inference options\n",
    "sample_options = {\n",
    "    \"tune\": 1000,\n",
    "    \"draws\": 1000,\n",
    "    \"chains\": 2,\n",
    "    \"cores\": 2,\n",
    "    \"nuts_kwargs\": {\"target_accept\": 0.95},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the high level code - what we want to do\n",
    "We want to loop through a range of parameter correlations, creating a set of true parameter values with a given correlation coefficient, then inferring those parameters. Then we can plot the actual parameter correlations with the recovered correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_sweep(r_vals, N):\n",
    "    \"\"\"Run a sweep across provided r values. Each time we generate \n",
    "    true parameters with desired correlations, and do parameter recovery\"\"\"\n",
    "\n",
    "    actual = []\n",
    "    recovered = []\n",
    "\n",
    "    for i, r in enumerate(r_vals):\n",
    "\n",
    "        print(f\"\\n\\nGroup number {i} of {len(r_vals)}\\n\")\n",
    "\n",
    "        params = generate_true_params(r=r, N=N)\n",
    "\n",
    "        # visualise the parameters + discount functions for this group\n",
    "        if export_group_plots:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "            plot_params_and_dfs(ax, params)\n",
    "            fig.suptitle(f\"True correlation coefficient = {r}\")\n",
    "            plt.savefig(\n",
    "                f\"output/corr_recovery_group{i}.pdf\", bbox_inches=\"tight\", dpi=300\n",
    "            )\n",
    "\n",
    "        recovered_params = do_parameter_recovery(params)\n",
    "\n",
    "        r_recovered, _ = pearsonr(recovered_params[:, 0], recovered_params[:, 1])\n",
    "\n",
    "        # record the correlation coefficient as the underlying one\n",
    "        # used to generate the true parameter values (from a multivarate\n",
    "        # normal), or the actual empirical one obtained from the samples\n",
    "        # from that distribution?\n",
    "        r_actual, _ = pearsonr(params[:, 0], params[:, 1])\n",
    "        # r_actual = r\n",
    "\n",
    "        actual.append(r_actual)\n",
    "        recovered.append(r_recovered)\n",
    "\n",
    "    return (actual, recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the low-level code to achieve this\n",
    "### Generate true parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_params(\n",
    "    r=0.0, logk_mean=np.log(1 / 50), logk_sigma=1.0, logs_mean=0, logs_sigma=0.2, N=20,\n",
    "):\n",
    "    \"\"\"Generate a set of parameter values (logk, logs) from a bivariate normal distribution\"\"\"\n",
    "\n",
    "    cov = logk_sigma * logs_sigma * r\n",
    "    covariance_matrix = [[logk_sigma ** 2, cov], [cov, logs_sigma ** 2]]\n",
    "\n",
    "    params = multivariate_normal([logk_mean, logs_mean], covariance_matrix).rvs(N)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise for a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = +0.25\n",
    "params = generate_true_params(r=r, N=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_params_and_dfs(ax, params):\n",
    "    \"\"\"ax must be list of 2 axes\"\"\"\n",
    "\n",
    "    # plot true parameters\n",
    "    ax[0].scatter(params[:, 0], np.exp(params[:, 1]))\n",
    "    ax[0].set(xlabel=r\"$\\log(k)$\", ylabel=r\"$s$\", title=\"params\")\n",
    "\n",
    "    # plot true discount functions\n",
    "    D = np.linspace(0, 100, 1000)\n",
    "\n",
    "    for θ in params:\n",
    "        logk, logs = θ[0], θ[1]\n",
    "        s, k = np.exp(logs), np.exp(logk)\n",
    "        y = 1 / (1 + (k * D) ** s)\n",
    "        ax[1].plot(D, y, \"k\", lw=3, alpha=0.1)\n",
    "\n",
    "    ax[1].set(\n",
    "        title=\"discount functions\", xlabel=\"delay [sec]\", ylabel=\"discount fraction\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "plot_params_and_dfs(ax, params)\n",
    "fig.suptitle(f\"True correlation coefficient = {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we are using $\\log(s)$ and $\\log(k)$, just we are plotting $s$ on the y axis for interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter recovery code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_parameter_recovery(params):\n",
    "\n",
    "    N_simulations = params.shape[0]\n",
    "    recovered_params = np.empty([N_simulations, N_PARAMETERS])\n",
    "\n",
    "    for i, θ in enumerate(params):\n",
    "\n",
    "        # get params into a tuple, get this the right way around!\n",
    "        logs, logk = θ[1], θ[0]\n",
    "        data_generating_params = (logs, logk)\n",
    "\n",
    "        # simulate data\n",
    "        expt_data = simulate_experiment(data_generating_params)\n",
    "        recovered_params[i, :] = infer_parameters(expt_data)\n",
    "\n",
    "        if should_visualise:\n",
    "            visualise(expt_data, data_generating_params, recovered_params[i, :])\n",
    "\n",
    "    return recovered_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_experiment(params_true, ϵ=0.01):\n",
    "    \"\"\"Run a simulated experiment, returning simulated behavioural data\"\"\"\n",
    "    designs = generate_designs()\n",
    "    responses, _ = generate_responses(designs, params_true, ϵ)\n",
    "    return pd.concat([designs, responses], axis=1)\n",
    "\n",
    "\n",
    "def generate_designs():\n",
    "    \"\"\"Generate designs (RA, DA, RB, DB). This should precisely match the \n",
    "    set of questions we used in the actual experiment.\"\"\"\n",
    "\n",
    "    n = 50\n",
    "    RA_vals = np.array([6, 12, 18, 24, 30, 36, 42, 48, 54, 60])\n",
    "    DB_vals = np.array([7, 15, 29, 56, 101])\n",
    "\n",
    "    # define constant values\n",
    "    DA = np.zeros(n)\n",
    "    RB = np.full(n, 60)\n",
    "\n",
    "    # shuffle index for DB\n",
    "    DB_index = np.arange(len(DB_vals))\n",
    "    np.random.shuffle(DB_index)\n",
    "\n",
    "    # fill remaining design dimensions by iterating over DB (shuffled) and RA\n",
    "    DB = []\n",
    "    RA = []\n",
    "    for db_index in DB_index:\n",
    "        for ra in RA_vals:\n",
    "            DB.append(DB_vals[db_index])\n",
    "            RA.append(ra)\n",
    "\n",
    "    DB = np.array(DB)\n",
    "    RA = np.array(RA)\n",
    "\n",
    "    designs = pd.DataFrame({\"RA\": RA, \"DA\": DA, \"RB\": RB, \"DB\": DB})\n",
    "    return designs\n",
    "\n",
    "\n",
    "def generate_responses(designs, params_true, ϵ):\n",
    "    \"\"\"Generate simulated responses for the given designs and parameters\"\"\"\n",
    "\n",
    "    # unpack designs\n",
    "    RA = designs[\"RA\"].values\n",
    "    DA = designs[\"DA\"].values\n",
    "    RB = designs[\"RB\"].values\n",
    "    DB = designs[\"DB\"].values\n",
    "\n",
    "    # unpack parameters\n",
    "    logs, logk = params_true\n",
    "\n",
    "    k = np.exp(logk)\n",
    "    s = np.exp(logs)\n",
    "\n",
    "    VA = RA * (1 / (1 + (k * DA) ** s))\n",
    "    VB = RB * (1 / (1 + (k * DB) ** s))\n",
    "    decision_variable = VB - VA\n",
    "    p_choose_B = ϵ + (1 - 2 * ϵ) * (1 / (1 + np.exp(-1.7 * decision_variable)))\n",
    "    responses = bernoulli.rvs(p_choose_B)\n",
    "    return pd.DataFrame({\"R\": responses}), p_choose_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_experiment((np.log(1), -2.0)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter estimation (inference) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_parameters(data):\n",
    "    \"\"\"Infer parameter values based on response data.\n",
    "    Return the posterior mean parameter estimates\"\"\"\n",
    "\n",
    "    model = generate_model(data)\n",
    "\n",
    "    # do the inference\n",
    "    with model:\n",
    "        trace = pm.sample(**sample_options)\n",
    "\n",
    "    return np.array([np.mean(trace[\"logs\"]), np.mean(trace[\"logk\"])])\n",
    "\n",
    "\n",
    "def generate_model(data):\n",
    "    \"\"\"Generate a PyMC3 model with the given observed data\"\"\"\n",
    "\n",
    "    # decant data\n",
    "    R = data[\"R\"].values\n",
    "    RA, DA = data[\"RA\"].values, data[\"DA\"].values\n",
    "    RB, DB = data[\"RB\"].values, data[\"DB\"].values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # define priors\n",
    "        logk = pm.Normal(\"logk\", mu=np.log(1 / 30), sd=3)\n",
    "        logs = pm.Normal(\"logs\", mu=0, sd=1)\n",
    "\n",
    "        VA = pm.Deterministic(\"VA\", value_function(RA, DA, logk, logs))\n",
    "        VB = pm.Deterministic(\"VB\", value_function(RB, DB, logk, logs))\n",
    "        P_chooseB = pm.Deterministic(\"P_chooseB\", choice_psychometric(VB - VA))\n",
    "\n",
    "        R = pm.Bernoulli(\"R\", p=P_chooseB, observed=R)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# helper functions for the model\n",
    "\n",
    "\n",
    "def value_function(reward, delay, logk, logs):\n",
    "    \"\"\"Calculate the present subjective value of a given prospect\"\"\"\n",
    "    k = pm.math.exp(logk)\n",
    "    s = pm.math.exp(logs)\n",
    "    return reward / (1.0 + (k * delay) ** s)\n",
    "\n",
    "\n",
    "def choice_psychometric(x, ϵ=0.01):\n",
    "    # x is the decision variable\n",
    "    return ϵ + (1.0 - 2.0 * ϵ) * (1 / (1 + pm.math.exp(-1.7 * (x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to simulate an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(data, data_generating_params, recovered_params):\n",
    "    \"\"\"Visualise the results of a simulated experiment\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    plt.scatter(data.DB, data.RA / data.RB, c=data.R)\n",
    "\n",
    "    D = np.linspace(0, 100, 1000)\n",
    "\n",
    "    # plot recovered\n",
    "    logs, logk = recovered_params[0], recovered_params[1]\n",
    "    s, k = np.exp(logs), np.exp(logk)\n",
    "    y = 1 / (1 + (k * D) ** s)\n",
    "    plt.plot(D, y, \"r\", alpha=0.5, lw=2, label=\"recovered\")\n",
    "\n",
    "    # plot true\n",
    "    logs, logk = data_generating_params\n",
    "    s, k = np.exp(logs), np.exp(logk)\n",
    "    y = 1 / (1 + (k * D) ** s)\n",
    "    plt.plot(D, y, \"k\", lw=2, label=\"true\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise before the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate(r_vals):\n",
    "\n",
    "    params = generate_true_params(r=r, N=N)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "    plot_params_and_dfs(ax, params)\n",
    "    fig.suptitle(f\"True correlation coefficient = {r}\")\n",
    "    plt.savefig(f\"output/corr_recovery_group{i}.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run the actual parameter sweep over _r_ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, recovered = r_sweep(r_vals=r_vals, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(actual, recovered)\n",
    "ax.plot([-1, 1], [-1, 1], \"k\")\n",
    "ax.set(\n",
    "    title=f\"Recovery of parameter correlations\\n(group size = {N})\",\n",
    "    xlabel=\"actual correlation coefficient\",\n",
    "    ylabel=\"recovered correlation coefficient\",\n",
    ")\n",
    "\n",
    "plt.savefig(\"output/r_recovery.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- Vincent, B. T., & Stewart, N. (2020). The case of muddled units in temporal discounting. _Cognition_, 198, 1-11. https://doi.org/10.1016/j.cognition.2020.104203"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
