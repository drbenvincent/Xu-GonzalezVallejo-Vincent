{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimation\n",
    "Running this notebook will to the parameter estimation for an experiment. Set the `expt` parameter to decide which experiment to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data + modelling\n",
    "import numpy as np\n",
    "import numpy.matlib  # for repmat, used in calc_log_loss()\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import math\n",
    "import os\n",
    "from sklearn.metrics import log_loss\n",
    "import random\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "from plotting import plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Define sampler options\n",
    "sample_options = {'tune': 2000, 'draws': 5000,\n",
    "                  'chains': 4, 'cores': 4,\n",
    "                  'nuts_kwargs': {'target_accept': 0.95},\n",
    "                  'random_seed': SEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOULD_SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'output/'\n",
    "\n",
    "# ensure output folder exists\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "# ensure subfolders exist\n",
    "for expt in [1, 2]:\n",
    "    desired = f'{out_dir}expt{expt}/'\n",
    "    if not os.path.exists(desired):\n",
    "        os.makedirs(desired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment specific information\n",
    "\n",
    "NOTE: Set the `expt` variable to either 1 or 2 and run the notebook to do parameter estimation for that experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = 2\n",
    "data_file = f'raw_data_expt{expt}/EXPERIMENT{expt}DATA.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a participant/group lookup table\n",
    "This is needed so that we can look up the group (ie condition) that a participant belongs to. Want an array with one entry for each participant, the value of which is the condition number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([data['id'].values, data['condition'].values]).T\n",
    "temp = np.unique(temp, axis=0)\n",
    "group = temp[:,1]\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = np.max(group)+1\n",
    "n_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_participants = max(data.id)+1\n",
    "n_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RA = data['RA'].values\n",
    "RB = data['RB'].values\n",
    "DA = data['DA'].values\n",
    "DB = data['DB'].values\n",
    "R = data['R'].values\n",
    "p = data['id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PyMC3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def V(reward, delay, logk, logs):\n",
    "    '''Calculate the present subjective value of a given prospect'''\n",
    "    k = pm.math.exp(logk)\n",
    "    s = pm.math.exp(logs)\n",
    "    return reward * discount_function(delay, k, s)\n",
    "\n",
    "\n",
    "def discount_function(delay, k, s):\n",
    "    ''' This is the MODIFIED Rachlin discount function. This is outlined\n",
    "    in Vincent & Stewart (2018).\n",
    "    Vincent, B. T., & Stewart, N. (2018, October 16). The case of muddled\n",
    "    units in temporal discounting. https://doi.org/10.31234/osf.io/29sgd\n",
    "    '''\n",
    "    return 1 / (1.0+(k*delay)**s)\n",
    "\n",
    "\n",
    "def Î¦(VA, VB, Ïµ=0.01):\n",
    "    '''Psychometric function which converts the decision variable (VB-VA)\n",
    "    into a reponse probability. Output corresponds to probability of choosing\n",
    "    the delayed reward (option B).'''\n",
    "    return Ïµ + (1.0-2.0*Ïµ) * (1/(1+pm.math.exp(-1.7*(VB-VA))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical model with groups\n",
    "# Different (k, s) parameters for each participant\n",
    "# Each participant also comes from a group\n",
    "\n",
    "g = [0, 1, 2, 3]\n",
    "\n",
    "with pm.Model() as group_model:\n",
    "    '''Hierachical model with trials, participants, and groups. \n",
    "    Different (k,s) parameters for each participant. \n",
    "    Each participant comes from one of 4 groups.\n",
    "    \n",
    "    Observed data:\n",
    "    - RA, DA, RB, DB, R: trial level data\n",
    "    - group: list of group membership for each participant \n",
    "    - g: equals [0, 1, 2, 3] just used for group level inferences about (logk, logs)\n",
    "    '''\n",
    "    \n",
    "    # Hyperpriors \n",
    "    mu_logk = pm.Normal('mu_logk', mu=math.log(1/30), sd=2, shape=n_groups)\n",
    "    sigma_logk = pm.Exponential('sigma_logk', 10, shape=n_groups)\n",
    "    \n",
    "    mu_logs = pm.Normal('mu_logs', mu=0, sd=0.5, shape=n_groups)\n",
    "    sigma_logs = pm.Exponential('sigma_logs', 20, shape=n_groups)\n",
    "    \n",
    "    # Priors over parameters for each participant \n",
    "    logk = pm.Normal('logk', mu=mu_logk[group], sd=sigma_logk[group], shape=n_participants) \n",
    "    logs = pm.Normal('logs', mu=mu_logs[group], sd=sigma_logs[group], shape=n_participants) \n",
    "    \n",
    "    # group level inferences, unattached from the data\n",
    "    group_logk = pm.Normal('group_logk', mu=mu_logk[g], sd=sigma_logk[g], shape=4) \n",
    "    group_logs = pm.Normal('group_logs', mu=mu_logs[g], sd=sigma_logs[g], shape=4)\n",
    "    \n",
    "    # Choice function: psychometric\n",
    "    P = pm.Deterministic('P', Î¦(V(RA, DA, logk[p], logs[p]),\n",
    "                                V(RB, DB, logk[p], logs[p])) )\n",
    "    \n",
    "    # Likelihood of observations\n",
    "    R = pm.Bernoulli('R', p=P, observed=R)\n",
    "\n",
    "    \n",
    "pm.model_to_graphviz(group_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with group_model:\n",
    "    prior = pm.sample_prior_predictive(10_000)\n",
    "    \n",
    "logk = prior['group_logk']\n",
    "logk = logk.flatten()\n",
    "\n",
    "logs = prior['group_logs']\n",
    "logs = logs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'logk mean = {np.mean(logk)}, variance = {np.var(logk)}')\n",
    "print(f'logs mean = {np.mean(logs)}, variance = {np.var(logs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.log(1/30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a figure to demonstrate the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 15))\n",
    "gs = gridspec.GridSpec(3, 2)\n",
    "\n",
    "# log\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "sns.distplot(logk, ax=ax)\n",
    "ax.set(xlabel=r'$\\ln(k)$', ylabel='prior density', title=\"(a)\")\n",
    "\n",
    "ax = fig.add_subplot(gs[0,1])\n",
    "sns.distplot(logs, ax=ax)\n",
    "ax.set(xlabel=r'$\\ln(s)$', ylabel='prior density', title=\"(b)\")\n",
    "\n",
    "# plot discount functions, sampled from prior\n",
    "ax = fig.add_subplot(gs[1:2,:])\n",
    "\n",
    "n_samples_to_plot = 500\n",
    "delays = np.linspace(0, 101, 500)\n",
    "for n in range(n_samples_to_plot):\n",
    "    ax.plot(delays, discount_function(delays, np.exp(logk[n]), np.exp(logs[n])),\n",
    "            c='k', alpha=0.1)\n",
    "\n",
    "ax.set(xlabel=\"delay [seconds]\", \n",
    "       ylabel='discount fraction\\n$1/(1+(k \\cdot delay)^s)$', \n",
    "       title=\"(c)\",\n",
    "       xlim=[0, 101],\n",
    "       ylim=[0, 1])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if SHOULD_SAVE:\n",
    "    plt.savefig(f'{out_dir}priors.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with group_model:\n",
    "    trace = pm.sample(**sample_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "Check the posterior is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.energyplot(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export parameter estimate table\n",
    "First we define some functions to calculate measures derived from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_AUC(logk, logs, max_delay=101):\n",
    "    '''Calculate Area Under Curve measure'''\n",
    "    delays = np.linspace(0, max_delay, 500)\n",
    "    df = discount_function(delays, np.exp(logk), np.exp(logs))\n",
    "    normalised_delays = delays / np.max(delays)\n",
    "    AUC = np.trapz(df, x=normalised_delays)\n",
    "    return AUC\n",
    "\n",
    "\n",
    "def calc_percent_predicted(R_predicted_prob, R_actual):\n",
    "    nresponses = R_actual.shape[0]\n",
    "    predicted_responses = np.where(R_predicted_prob>0.5, 1, 0)\n",
    "    n_correct = sum(np.equal(predicted_responses, R_actual))\n",
    "    return  n_correct / nresponses\n",
    "\n",
    "\n",
    "def calc_log_loss(R_predicted_prob, R_actual):\n",
    "    return log_loss(R_actual, R_predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rowdata(id, logk, logs, pdata, Ractual, Ppredicted):\n",
    "    logk_point_estimate = np.mean(logk)\n",
    "    logs_point_estimate = np.mean(logs)\n",
    "    if expt is 1:\n",
    "        rowdata = {'id': [id],\n",
    "                   'PID': pdata['Participant'].reset_index(drop=True)[0],\n",
    "                   'logk': [logk_point_estimate], \n",
    "                   'logs': [logs_point_estimate], \n",
    "                   'paradigm': [pdata['paradigm'].values[0]], \n",
    "                   'reward_mag': [pdata['reward_mag'].values[0]], \n",
    "                   'AUC': calc_AUC(logk_point_estimate, logs_point_estimate), \n",
    "                   'percent_predicted': calc_percent_predicted(np.median(Ppredicted, axis=0), Ractual),\n",
    "                   'log_loss': calc_log_loss(np.median(Ppredicted, axis=0), Ractual)}\n",
    "    elif expt is 2:\n",
    "        rowdata = {'id': [id],\n",
    "                   'PID': pdata['Participant'].reset_index(drop=True)[0],\n",
    "                   'logk': [logk_point_estimate], \n",
    "                   'logs': [np.mean(logs)], \n",
    "                   'paradigm': [pdata['paradigm'].values[0]], \n",
    "                   'domain': [pdata['domain'].values[0]], \n",
    "                   'AUC': calc_AUC(logk_point_estimate, logs_point_estimate), \n",
    "                   'percent_predicted': calc_percent_predicted(np.median(Ppredicted, axis=0), Ractual),\n",
    "                   'log_loss': calc_log_loss(np.median(Ppredicted, axis=0), Ractual)}\n",
    "    return pd.DataFrame.from_dict(rowdata)\n",
    "     \n",
    "\n",
    "rows = []\n",
    "for id in range(n_participants):\n",
    "    logk = trace['logk'][:,id]\n",
    "    logs = trace['logs'][:,id]\n",
    "    P_chooseB = trace['P'][:,id]\n",
    "\n",
    "    pdata = data.loc[data['id'] == id]\n",
    "\n",
    "    Ppredicted = trace.P[:, data['id'] == id]\n",
    "    Ractual = pdata['R'].values\n",
    "\n",
    "    rowdata = make_rowdata(id, logk, logs, pdata, Ractual, Ppredicted)\n",
    "    rows.append(rowdata)\n",
    "    # print(f'{id+1} of {n_participants}')\n",
    "\n",
    "\n",
    "parameter_estimates = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "if SHOULD_SAVE:\n",
    "    parameter_estimates.to_csv(f'analysis/EXPERIMENT_{expt}_RESULTS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['logk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['logs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace, varnames=['group_logk', 'group_logs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise posterior predictions for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_plot(i, trace, data, n_samples_to_plot=100, max_delay=365):\n",
    "    '''Plot information about a participant. \n",
    "    Posterior inferences in parameter space.\n",
    "    Data and posterior predictive checking in data space.'''\n",
    "    \n",
    "    logk = trace['group_logk'][:,i]\n",
    "    logs = trace['group_logs'][:,i]\n",
    "\n",
    "    delays = np.linspace(0, max_delay, 1000)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax[0].scatter(logk, logs, alpha=0.1)\n",
    "    ax[0].set(xlabel='logk', ylabel='logs', title='parameter space')\n",
    "\n",
    "    # plot discount functions, sampled from the posterior\n",
    "    for n in range(n_samples_to_plot):\n",
    "        ax[1].plot(delays, discount_function(delays, np.exp(logk[n]), np.exp(logs[n])),\n",
    "                   c='k', alpha=0.1)\n",
    "\n",
    "    ax[1].set(xlabel='delay [seconds]', ylabel='RA/RB', title='data space');\n",
    "    \n",
    "for group in range(4):\n",
    "    group_plot(group, trace, data)\n",
    "    plt.savefig(f'{out_dir}expt{expt}/group{group}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if expt is 1:\n",
    "    group_name = ['Deferred, low',\n",
    "                  'Online, low',\n",
    "                  'Deferred, high',  \n",
    "                  'Online, high']\n",
    "elif expt is 2:\n",
    "    group_name = ['Deferred, gain',\n",
    "                  'Online, gain',\n",
    "                  'Deferred, loss', \n",
    "                  'Online, loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "\n",
    "for i in range(4):\n",
    "    logk = trace['group_logk'][:,i]\n",
    "    logs = trace['group_logs'][:,i]\n",
    "    ax.scatter(logk, logs, alpha=0.01, label=group_name[i])\n",
    "    \n",
    "leg = ax.legend()\n",
    "\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "    \n",
    "ax.set(xlabel='logk', ylabel='logs', title='parameter space')\n",
    "\n",
    "if SHOULD_SAVE:\n",
    "    plt.savefig(f'{out_dir}expt{expt}/group_param_space.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise group mean parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "\n",
    "for i in range(4):\n",
    "    logk = trace['mu_logk'][:,i]\n",
    "    logs = trace['mu_logs'][:,i]\n",
    "    ax.scatter(logk, logs, alpha=0.01, label=group_name[i])\n",
    "    \n",
    "leg = ax.legend()\n",
    "\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "\n",
    "ax.set(xlabel='logk', ylabel='logs', title=f'Experiment {expt}')\n",
    "\n",
    "if SHOULD_SAVE:\n",
    "    plt.savefig(f'{out_dir}expt{expt}/group_mean_estimates_in_param_space.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=1\n",
    "pdata = data.loc[data['id'] == id]\n",
    "pdata['RB'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant level plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_plot(id, trace, data, n_samples_to_plot=100, legend=True):\n",
    "    '''Plot information about a participant. \n",
    "    Posterior inferences in parameter space.\n",
    "    Data and posterior predictive checking in data space.'''\n",
    "    \n",
    "    logk = trace['logk'][:,id]\n",
    "    logs = trace['logs'][:,id]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # PARAMETER SPACE ==================================\n",
    "    ax[0].scatter(logk, logs, alpha=0.1)\n",
    "    ax[0].set(xlabel='logk', ylabel='logs', title='parameter space')\n",
    "\n",
    "    # DATA SPACE =======================================\n",
    "    plot_data_space(id, ax[1], data, logk, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_space(id, ax, data, logk, logs, n_samples_to_plot=50):\n",
    "    \n",
    "    # plot the data\n",
    "    pdata = data.loc[data['id'] == id]\n",
    "    plot_data(pdata, ax, legend=False)\n",
    "    \n",
    "    # plot discount functions\n",
    "    max_delay = np.max(pdata['DB'].values) * 1.1\n",
    "    delays = np.linspace(0, max_delay, 1000)\n",
    "    \n",
    "    # plot discount functions, sampled from the posterior\n",
    "    for n in range(n_samples_to_plot):\n",
    "        RB = pdata['RB'].values[0]\n",
    "        ax.plot(delays, \n",
    "                RB*discount_function(delays, np.exp(logk[n]), np.exp(logs[n])),\n",
    "                c='k', alpha=0.1)\n",
    "    # plot median discount rate\n",
    "    ax.plot(delays, \n",
    "                RB*discount_function(delays, np.exp(np.median(logk[n])), np.exp(np.median(logs[n]))),\n",
    "                c='k', linewidth=3)\n",
    "    \n",
    "    # plot participant id info text\n",
    "    if pdata['RB'].values[0] > 0:\n",
    "        text_y = 1.\n",
    "    elif pdata['RB'].values[0] < 0:\n",
    "        text_y = -1.\n",
    "        \n",
    "    ax.text(2, text_y, f'participant id: {id}',\n",
    "         horizontalalignment='left',\n",
    "         verticalalignment='center', #transform = ax.transAxes,\n",
    "         fontsize=10)\n",
    "        \n",
    "    ax.set(xlabel='delay [seconds]', \n",
    "           ylabel='immediate reward [cents]')\n",
    "    ax.set_xlim(left=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_plot(0, trace, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ”¥ Export all participant level plots. This takes a while to do. ðŸ”¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOULD_SAVE:\n",
    "    for id in range(n_participants):\n",
    "        print(f'{id} of {n_participants}')\n",
    "        participant_plot(id, trace, data, legend=False)\n",
    "\n",
    "\n",
    "        savename = f'{out_dir}expt{expt}/id{id}.pdf'\n",
    "        plt.savefig(savename, bbox_inches='tight')\n",
    "\n",
    "        # Close the figure to avoid very heavy plotting inside the notebook\n",
    "        plt.close(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo figure\n",
    "We are going to plot example data + parameter estimates for each condition (row) and a number of randomly chosen participants in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_in_condition(data, condition):\n",
    "    '''Return a list of id's in this condition'''\n",
    "    return data[data['condition'] == condition].id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "N_EXAMPLES = 3  # number of columns\n",
    "\n",
    "fig, ax = plt.subplots(4, N_EXAMPLES, figsize=(15, 13))\n",
    "\n",
    "# Ording of these is crucial... see the data import notebook for the key\n",
    "if expt is 1:\n",
    "    row_headings = ['Deferred, low',\n",
    "                    'Online, low',\n",
    "                    'Deferred, high',  \n",
    "                    'Online, high']\n",
    "elif expt is 2:\n",
    "    row_headings = ['Deferred, gain',\n",
    "                    'Online, gain',\n",
    "                    'Deferred, loss', \n",
    "                    'Online, loss']\n",
    "                \n",
    "pad = 13 # in points\n",
    "for axis, row_title in zip(ax[:,0], row_headings):\n",
    "    axis.annotate(row_title, xy=(0, 0.5), xytext=(-axis.yaxis.labelpad - pad, 0),\n",
    "                  xycoords=axis.yaxis.label, textcoords='offset points',\n",
    "                  size='large', ha='center', va='center', rotation=90)\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "# plot stuff\n",
    "for condition in [0, 1, 2, 3]:\n",
    "    \n",
    "    # get 3 participants who took part in this condition\n",
    "    valid_ids = ids_in_condition(data, condition)\n",
    "    ids = np.random.choice(valid_ids, N_EXAMPLES)\n",
    "    \n",
    "    \n",
    "    for col, exemplar_id in enumerate(ids):        \n",
    "        plot_data_space(exemplar_id, ax[condition, col], data,\n",
    "                        trace['logk'][:,exemplar_id], trace['logs'][:,exemplar_id])\n",
    "        \n",
    "fig.tight_layout()\n",
    "\n",
    "# selectively remove x labels\n",
    "for condition in [0, 1, 2]:\n",
    "    for exemplar in [0, 1, 2]:\n",
    "        ax[condition, exemplar].set(xlabel=None)\n",
    "        \n",
    "# selectively remove y labels\n",
    "for condition in [0, 1, 2, 3]:\n",
    "    for exemplar in [1, 2]:\n",
    "        ax[condition, exemplar].set(ylabel=None)\n",
    "        \n",
    "if SHOULD_SAVE:\n",
    "    plt.savefig(f'{out_dir}example_fits_experiment{expt}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
